{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpmath as mp\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "from tabulate import tabulate\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.collocations import *\n",
    "from datetime import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a variable which stores the corpus. This makes the code relatively modular since only the value of the variable has to be changed in order to test with different corpora.\n",
    "\n",
    "The corpus used for testing is the academic1 corpus in the Maltese set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Corpus/academic1.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function upon called returns the memory currently being used by python.exe in GBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAMusage():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0]/2.**30\n",
    "    print('Memory Use: ', memoryUse, 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Symbols from the Corpus in order for the Language Models, Perplexities and Sentence Generators to focus solely on only words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveSymbols(corpus):\n",
    "    arr = []\n",
    "    symbols = \"“”‘’!\\\"#$€%&()*'+-,./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    \n",
    "    for i in corpus:\n",
    "        if i not in symbols:\n",
    "            arr.append(i)\n",
    "            \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other attempts to read corpus in a more efficient manner:\n",
    "\n",
    "rawcorpus_dir = 'E:\\Corpus\\\\'\n",
    "\n",
    "output_dir = 'Corpus\\KorpusMalti.csv'\n",
    "\n",
    "csvout = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir('Corpus'):\n",
    "\n",
    "    data = pd.read_csv(filename, sep = ':', index_col = 0, header = None)\n",
    "    csvout.csvout.append(data)\n",
    "        \n",
    "csvout.to_csv(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Use:  0.1607208251953125 GB\n",
      "Extraction Time(HH::MM:SS:ms) - 0:00:01.345009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extraction_start = datetime.now()\n",
    "\n",
    "file = open(path)\n",
    "corpus = file.read()\n",
    "\n",
    "tokenize = word_tokenize(corpus)\n",
    "tokens = RemoveSymbols(tokenize)\n",
    "\n",
    "extraction_end = datetime.now()\n",
    "\n",
    "extraction_time = dict()\n",
    "extraction_time['extraction_time'] = extraction_end - extraction_start\n",
    "RAMusage()\n",
    "print('Extraction Time(HH::MM:SS:ms) - {}\\n\\n'.format(extraction_time['extraction_time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NGrams(words, n):\n",
    "    ngrams = []\n",
    "    \n",
    "    for i in range(0, len(words)):\n",
    "        ngram = ' '.join(words[i:i + n])\n",
    "        ngrams.append(ngram)\n",
    "        \n",
    "    return ngrams\n",
    "\n",
    "bigram = NGrams(tokens, 5)\n",
    "#freqdist = nltk.FreqDist(bigrams)\n",
    "\n",
    "#for i,j in freqdist.items():\n",
    "    #print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Split(corpus):\n",
    "    \n",
    "    file = open(path)\n",
    "    corpus = file.read()\n",
    "    words = []\n",
    "    \n",
    "    for line in corpus:\n",
    "        \n",
    "        words.append(line)\n",
    "        \n",
    "    train, test = train_test_split(words, test_size = 0.66, train_size = 0.34, shuffle = False)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "x, y = Split(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perplexity(test, model):\n",
    "    \n",
    "    perp = mp.mpf(1)\n",
    "    \n",
    "    N = mp.mpf(0)\n",
    "    \n",
    "    for line in test:\n",
    "        N += len(line)\n",
    "        line = ' '.join(line)\n",
    "        \n",
    "        if model[line] > 0:\n",
    "            perp = perp * (1/model[line])\n",
    "        else:\n",
    "            perp = perp * sys.maxsize\n",
    "            \n",
    "    perp = pow(perp, 1/float(N))\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Building a Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VanillaUnigram(train):\n",
    "    \n",
    "    model = Counter(train)\n",
    "    \n",
    "    for word in model:\n",
    "        model[word] = model[word]/len(train)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def VanillaBigram(train):\n",
    "    \n",
    "    model = Counter([(word, train[i + 1]) for i, word in enumerate(train[:-1])])\n",
    "    counter = Counter(train)\n",
    "    \n",
    "    for word in model:\n",
    "        model[word] = model[word]/counter[word[0]]\n",
    "        \n",
    "    return model\n",
    "\n",
    "def VanillaTrigram(train):\n",
    "    \n",
    "    bigram = Counter([(word, train[i + 1]) for i, word in enumerate(train[:-1])])\n",
    "    trigram = Counter([(word, train[i + 1], train[i + 2]) for i, word in enumerate(train[:-2])])\n",
    "    \n",
    "    for word in trigram:\n",
    "        trigram[word] = trigram[word]/bigram[(word[0], word[1])]\n",
    "        \n",
    "    return trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = VanillaUnigram(x)\n",
    "p1 = (Perplexity(y, a))\n",
    "\n",
    "b = VanillaBigram(x)\n",
    "p2 = (Perplexity(y, b))\n",
    "\n",
    "c = VanillaTrigram(x)\n",
    "p3 = (Perplexity(y, c))\n",
    "\n",
    "i1 = (Interpolation(a, b, c, [\"<s>\", \"</s>\"], \"il-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LaplaceUnigram(train):\n",
    "    \n",
    "    model = Counter(train)\n",
    "    \n",
    "    for word in model:\n",
    "        model[word] = (model[word]+1)/len(train)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def LaplaceBigram(train):\n",
    "    \n",
    "    model = Counter([(word, train[i + 1]) for i, word in enumerate(train[:-1])])\n",
    "    counter = Counter(train)\n",
    "    \n",
    "    for word in model:\n",
    "        model[word] = model[word] + 1/counter[word[0], word[1]]\n",
    "        \n",
    "    return model\n",
    "\n",
    "def LaplaceTrigram(train):\n",
    "    \n",
    "    bigram = Counter([(word, train[i + 1]) for i, word in enumerate(train[:-1])])\n",
    "    trigram = Counter([(word, train[i + 1], train[i + 2]) for i, word in enumerate(train[:-2])])\n",
    "    \n",
    "    for word in trigram:\n",
    "        trigram[word] = trigram[word] + 1 /bigram[(word[0], word[1], word[2])]\n",
    "        \n",
    "    return trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = LaplaceUnigram(x)\n",
    "p4 = (Perplexity(y, a2))\n",
    "\n",
    "#b2 = LaplaceBigram(x)\n",
    "#p5 = (Perplexity(y, b2))\n",
    "\n",
    "#c2 = LaplaceTrigram(x)\n",
    "#p6 = (Perplexity(y, c2))\n",
    "\n",
    "#i2 = (Interpolation(a2, b2, c2, [\"<s>\", \"</s>\"], \"il\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNKUnigram(train):\n",
    "    \n",
    "    counter = Counter(train)\n",
    "    model = {}\n",
    "    model[\"<UNK>\"] = 0\n",
    "    \n",
    "    for word in counter:\n",
    "        if counter[word] == 1:\n",
    "            model[\"<UNK>\"] += 1\n",
    "            \n",
    "        else:\n",
    "            model[word] = counter[word]\n",
    "            \n",
    "    for word in model:\n",
    "        model[word] = model[word]/len(train)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def UNKBigram(train):\n",
    "    \n",
    "    unigram = UNKUnigram(train)\n",
    "    \n",
    "    for i, word in enumerate(train):\n",
    "        if not (word in unigram):\n",
    "            train[i] = \"<UNK>\"\n",
    "            \n",
    "    return VanillaBigram(train)\n",
    "\n",
    "def UNKTrigram(train):\n",
    "    \n",
    "    unigram = UNKUnigram(train)\n",
    "    \n",
    "    for i, word in enumerate(train):\n",
    "        if not (word in unigram):\n",
    "            train[i] = \"<UNK>\"\n",
    "            \n",
    "    return VanillaTrigram(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = UNKUnigram(x)\n",
    "#p7 = (Perplexity(y, a3))\n",
    "\n",
    "b3 = UNKBigram(x)\n",
    "p8 = Perplexity(y, b3)\n",
    "\n",
    "c3 = UNKTrigram(x)\n",
    "p9 = (Perplexity(y, c3))\n",
    "\n",
    "#i3 = (Interpolation(a3, b3, c3, [\"<s>\", \"</s>\"], \"il\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = [\"Model\", \"Unigram\", \"Bigram\", \"Trigram\", \"Interpolation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+------------------+-----------+\n",
      "| Model                |     Unigram | Bigram           | Trigram   |\n",
      "+======================+=============+==================+===========+\n",
      "| 9.22337203685476e+18 | 0           | 34.9366920882137 | Vanilla   |\n",
      "+----------------------+-------------+------------------+-----------+\n",
      "| Laplace              | 0           | 34.9201727634248 |           |\n",
      "+----------------------+-------------+------------------+-----------+\n",
      "| 0                    | 9.22337e+18 | UNK              |           |\n",
      "+----------------------+-------------+------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "data = [{\"Vanilla\", p1, p2, p3, i1},\n",
    "        {\"Laplace\", p4, 0, 0, 0},\n",
    "        {\"UNK\", 0, p8, p9 , 0}]\n",
    "\n",
    "print(\"Vanilla Model: \", \"Unigram: \", p1, \"Bigram: \", p2, \"Trigram: \", p3, \"Interpolation: \", i1)\n",
    "print(\"\\n\")\n",
    "print(\"Laplace Model: \", \"Unigram: \", p4, \"Bigram: \", p2, \"Trigram: \", p3, \"Interpolation: \", i1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnigramProbability(unigram, sentence, word):\n",
    "    return unigram[word]\n",
    "\n",
    "def BigramProbability(bigram, sentence, word):\n",
    "    if (sentence[-1], word) in bigram:\n",
    "        return bigram[sentence[-1],word]\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def TrigramProbability(trigram, sentence, word): \n",
    "    if (sentence[-2],sentence[-1], word) in trigram:\n",
    "        return trigram[sentence[-2],sentence[-1],word]\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def Interpolation(unigram, bigram, trigram, sentence, word):\n",
    "    Unigram = 0.1*(unigram[word])\n",
    "    Bigram = 0.3*(bigram[sentence[-1], word])\n",
    "    Trigram = 0.6*(trigram[sentence[-2], sentence[-1], word])\n",
    "    \n",
    "    return Unigram+Bigram+Trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UnigramGenerate(unigram, sentence, last = \"\", count = None):\n",
    "    \n",
    "    if(count != 0 and sentence[-1] != last):\n",
    "        \n",
    "        weights = np.array(list(unigram.values()))\n",
    "        norm = weights/np.sum(weights)\n",
    "        \n",
    "        resample = np.random.multinomial(1, norm)\n",
    "        key = list(resample).index(1)\n",
    "        value = list(unigram.keys())[key]\n",
    "        \n",
    "        sentence.append(value)\n",
    "        if count != None:\n",
    "            UnigramGenerate(unigram, sentence, last, count-1)\n",
    "        else:\n",
    "            UnigramGenerate(unigram, sentence, last)\n",
    "            \n",
    "    return sentence\n",
    "\n",
    "#print(UnigramGenerate(a, [\"<s>\"], \"</s>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BigramGenerate(bigram, sentence, last, count = None):\n",
    "    \n",
    "    if(count != 0 and sentence != last):\n",
    "        bigrams = []\n",
    "        \n",
    "    for word in bigram:\n",
    "        if word[0] == sentence[-1]:\n",
    "            bigrams[word] = bigram[word]\n",
    "            \n",
    "    if(bigrams == []):\n",
    "        return sentence \n",
    "    \n",
    "    weights = np.array(list(bigrams.values()))\n",
    "    norm = weights / np.sum(weights)\n",
    "    resample = np.random.multinomial(1, norm)\n",
    "    key = list(resample).index(1)\n",
    "    value = list(bigrams.keys())[key]\n",
    "    \n",
    "    sentence.append(value)\n",
    "    \n",
    "    if count != None:\n",
    "        BigramGenerate(bigram, sentence, last, count-1)\n",
    "    else:\n",
    "        BigramGenerate(bigram, sentence, last)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrigramGenerate(bigram, trigram, sentence, last = \"\", count = None):\n",
    "    if(len(sentence) == 1):\n",
    "        sentence = BigramGenerate(bigram, sentence, last, count=1)\n",
    "        \n",
    "    if(count != 0 and sentence[-1] != last):\n",
    "        trigrams = []\n",
    "        \n",
    "        for word in trigram:\n",
    "            \n",
    "            if(word[0] == sentence[-2] and word[1] == sentence[-1]):\n",
    "                trigrams[word] = trigram[word]\n",
    "                \n",
    "        if(trigrams == []):\n",
    "            return sentence\n",
    "        \n",
    "        weights = np.array(list(bigrams.values()))\n",
    "        norm = weights / np.sum(weights)\n",
    "        resample = np.random.multinomial(1, norm)\n",
    "        key = list(resample).index(1)\n",
    "        value = list(bigrams.keys())[key] \n",
    "        \n",
    "        sentence.append(value[2])\n",
    "        if count != None:\n",
    "            TrigramGenerate(bigram, trigram, sentence, last, count-1)\n",
    "            \n",
    "        else:\n",
    "            TrigramGenerate(bigram, trigram, sentence, last)\n",
    "            \n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
